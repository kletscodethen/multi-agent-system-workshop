# Exercise 1 â€” Interacting with an LLM (Gemini)

Learn the minimal loop of sending a prompt to an LLM and receiving a response

## Steps
1. Connect via SDK - `@google/genai`
2. Generate content
3. Create a context window
4. Run an interactive session in the terminal

### Optional
- Adjust configuration options
- Experiment with stream mode

## Short exercise

Try different models and compare:
- Latency (how fast you get first token & full answer)
- Style (concise vs verbose)
- Cost/fit for purpose (flash vs pro)

Docs: https://ai.google.dev/gemini-api/docs/models